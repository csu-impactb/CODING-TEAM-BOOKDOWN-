[{"path":"index.html","id":"overview","chapter":"1 Overview","heading":"1 Overview","text":"","code":""},{"path":"index.html","id":"about-the-project","chapter":"1 Overview","heading":"1.1 About the project","text":"objective Immune Mechanisms Protection Mycobacterium tuberculosis (IMPAc-TB) program get thorough understanding immune responses necessary avoid initial infection Mycobacterium tuberculosis (Mtb), formation latent infection, progression active TB illness. achieve goals, National Institute Allergy Infectious Diseases awarded substantial funding established multidisciplinary research teams analyze immune responses Mtb animal models (mice, guinea pigs, non-human primates) humans, well immune responses elicited promising vaccine candidates. contract awards establish give seven years assistance IMPAc-TB Centers explain immune responses required Mtb infection protection.seven centers part study (alphabetical order):Colorado State UniversityHarvard T.H. Chan School Public HealthSeattle Children Hospital[]Colorado State University Team role member:Dr. Marcela Henao-Tamayo: Principal InvestigatorDr. Brendan Podell: Principal InvestigatorDr. Andres Obregon-Henao: Research Scientist-IIIDr. Taru S. Dutt: Research Scientist-[]","code":""},{"path":"index.html","id":"about-this-book","chapter":"1 Overview","heading":"1.2 About this book","text":"aim book provide data protocols data collection templates\nkey types data collected course project. using\nstandard templates record data, well starting defined pipelines \nprocess analyze data, aim standardize collection processing\ndata across project., built comprehensive guide wet lab data collection, sample processing, computational tool creation robust efficient data analysis dissemination.","code":""},{"path":"experimental-metadata.html","id":"experimental-metadata","chapter":"2 Experimental metadata","heading":"2 Experimental metadata","text":"Metadata experiment:speciesstart_dateend_dateexperimental_groups","code":""},{"path":"animal-initial-conditions-and-weekly-weights.html","id":"animal-initial-conditions-and-weekly-weights","chapter":"3 Animal initial conditions and weekly weights","heading":"3 Animal initial conditions and weekly weights","text":"","code":""},{"path":"animal-initial-conditions-and-weekly-weights.html","id":"downloads","chapter":"3 Animal initial conditions and weekly weights","heading":"3.0.1 Downloads","text":"downloads chapter :Data collection template collecting initial information experimental animals regular weight measurements, cage changes, adverse events throughout experimentReport template process data collected template (go link, go “File” bar browser’s menu bar, chose “Save ,” save file “animal_weights.Rmd”)Example output report template","code":""},{"path":"animal-initial-conditions-and-weekly-weights.html","id":"overview-1","chapter":"3 Animal initial conditions and weekly weights","heading":"3.0.2 Overview","text":"use template section record information animal\nused experiment. includes species, sex, experimental group.\nalso includes information identify animal, case\nmice includes code describing pattern notches put mouse’s\near cage animal assigned beginning \nexperiment. values can determined start \nexperiment, mice first assigned groups.template also used record data course \nexperiment. includes adverse events cases animal moved \none cage another experiment.addition, experiments, measuring mice every week record\nweight course experiment. weight measuring begins\nfirst vaccination continues last mouse \nsacrificed. used ear notches identify mouse, ear\nnotch mouse’s cage number, can uniquely track mouse \nstudy.reasons measuring mouse weights. first \nhelp us manage mice, particularly terms animal welfare. \nmice losing lot weight, can indication \nmay need euthanized. example, animal care standards consider \nadult animal lost 20% weight compared baseline\nweight indicating clear sign morbidity suffering.second reason weight measure might provide record \nmouse’s general health course study. study, mice \nweighed grams weekly monitor clinical status, one potential sign \ntuberculosis infection severity weight loss.humans, tuberculosis patients frequently display weight loss clinical\nsymptom associated disease progression. particular, extreme weight loss\nloss muscle mass, also known cachexia, can present result \nchronic inflammatory illnesses like tuberculosis (Baazim, Antonio-Herrera, Bergthaler 2022). \ncachexia part systemic response inflammation, humans \nlinked upregulation pro-inflammatory cytokines including tumor necrosis\nfactor, interleukin-6, interferon-gamma (Baazim, Antonio-Herrera, Bergthaler 2022).\nAdditionally, studies support role cachexia key immune cell populations\ncytotoxic T-cells , depleted, counteract muscle fat\ndeterioration (Baazim et al. 2019), suggest thsi type T-cells may\nmetabolically reprogram adipose tissue.Given relationships weight loss, diseases, immune processes,\npossible mouse weight might provide regularly measurable insight\nseverity disease animal. many data points\ncollected measure final disease state animal, fewer \navailable animal sacrificed. hoping mouse weights\nprovide one measure , may perfectly capture disease\nseverity, may provide information throughout experiment \ncorrelated disease severity regular time intervals.studies use mouse model tuberculosis collected mouse\nweights, well (Smith et al. 2022; Segueni et al. 2016). plan \ninvestigate data visualize trajectory weight gain / loss \nmouse challenged tuberculosis.\nalso plan test whether mouse’s weight change challenge\ncorrelated metrics severity disease immune response.\ntesting correlation percent change \nweight challenge sacrifice CFUs sacrifice well \nexpression cytokines biological markers (Smith et al. 2022).","code":""},{"path":"animal-initial-conditions-and-weekly-weights.html","id":"template-description","chapter":"3 Animal initial conditions and weekly weights","heading":"3.0.3 Template description","text":"animals’ initial conditions weekly measures (adverse events,\ncage changes, weights) recorded excel worksheet. can\ndownload copy template\n.worksheet divided sheets. first sheet recorded first\ntime point mice measured used record information \nmice remain unchanged course study, like species\nsex. first sheet template looks like:second later sheets used record weight measured timepoint.\nsecond sheet record weights first date measured, \nrecorded time first sheet—initial mouse\ninformation—completed. first sheet template looks like:continue measure new timepoints, add sheet \ntimepoint, new sheet following format second sheet \ntemplate. second later sheets labeled date \nweights measured (e.g., “5.26.22” weights measured May 26, 2022).download template, example values filled blue.\nUse get idea record data. ready\nrecord data, delete example values replace \ndata collected experiment.Column titles follows. First, first sheet, record:notch_id: Record ear notch pattern mouse. Make sure \nrecord consistently across timepoints, mouse can tracked\nacross dates. single notches, example, might “0”\nnotches, “1R” one notch right ear, “1L” one notch \nleft ear, “1R1L” one notch ear.starting_cage_number: Record number cage mouse put\nstart experiment. combination mouse’s notch_id,\nprovide unique identifier mouse start \nexperiment.dob: Record date mouse born.species: Record species mouse (e.g., “C57BL/6” C57 black 6 mice \n“CBA” CBA mice).sex: Record “m” male “f” femalegroup: Provide experimental group mouse. sure use \nabbreviation notation across timepoint. Examples group\ndesignations might : bcg, saline, bcg+id93, saline+id93, saline+noMtbFor second later sheets, record:who_collected: Record first name person actually handled mouse scale.date_collected: Record date using quotation marks, month, day, year. example, “May 31, 2022.”weight: Record number, without unit column. next column used units.unit: Provide units used take weight (e.g., “g” grams). consistent across animals timepoints abbreviation use (e.g., always use “g” grams, “g” sometimes “grams” sometimes)existing_cage_number: Provide cage number mouse start weighing time point. mouse moved another cage day, specify next column. animal moved one cage another last weighing date timepoint measuring, put column cage number animal last time weighed.new_cage_number: animal moved new cage date timepoint measuring, use column record number cage move . Similarly, animal moved cages last measured timepoint one, use column record cage moved . Otherwise, animal stays cage last measured time point, leave column empty.group: Provide experimental group mouse. sure use abbreviation notation across timepoint. Examples group designations might : bcg, saline, bcg+id93, saline+id93, saline+noMtbnotes: Record information regarding clinical observations (e.g., “back balding,” “barbering,” “excessive grooming,” “euthanized”).","code":""},{"path":"animal-initial-conditions-and-weekly-weights.html","id":"processing-collected-data","chapter":"3 Animal initial conditions and weekly weights","heading":"3.0.4 Processing collected data","text":"data collected, file can run R workflow. workflow\nconvert data format easier work data analysis\nvisualization. also produce report data spreadsheet, \nultimately also write relevant results format can used\npopulate global database experiments project.next section provides details pipeline. aims explain \ncode processes data generates visualizations. need \nrun code step--step, instead can access script full\ncode .use reporting template, need download computer \nsave file directory saved data collected \ndata collection template. can open RStudio navigate \nworking within directory. also make sure installed\nrequired packages R computer using run report.\npackages : tidyverse, purrr, lubridate, readxl, knitr, \nggbeeswarm.Within RStudio, open report template file. one spot \nneed change code template file, read data \nversion template saved, may renamed.\nYAML report template file, change file path beside “data:”\nfile name data file.’ve made change, can use “Knit” button RStudio \ncreate report data file report template file.report includes following elements:Summary table animals start experimentTime series plots animal weights experiment, grouped \nexperimental groupBoxplots distribution animal weights within experimental\ngroup last available time pointPlot measured weight, identified person handling \nanimal, help determine consistent differences handlerTable animals experiment last measured time point,\nordered weight change since previous measurement. table\nmeant help identifying animals may need euthanized \nanimal welfare reasons.can download example report created using template \nclicking .knit create report, create Word file \nfile directory put data file report template.\nalso create output version data \nprocessed (case weights data, mainly involves\ntracking mice change cages, link weights \nsingle animal). output fill named “…” , like\nreport file, saved file directory \ndata file report template.","code":""},{"path":"animal-initial-conditions-and-weekly-weights.html","id":"details-of-processing-script","chapter":"3 Animal initial conditions and weekly weights","heading":"3.0.5 Details of processing script","text":"section goes code within report template. \nexplains part code detail. need understand\ndetails use report template. However, questions\ndata processed, outputs created,\ndetails available section.note, two places following code ’s small\nchange compared report template. report, incorporate path\ndata file using data: section YAML top \ndocument. following code, ’ve instead used path example\ndata within book’s file directory, code run chapter \nwell.First, workflow loads additional R libraries. may need install\nlocal R session already installed.packages bring useful functions available \nbase installation R. open source. cite , \ncan use citation function. example, get information \nneed cite readxl package, R can run:Next, code report template creates custom functions \nhelp process data data collection template. first \nfunctions checks data collection template identify timepoints\ncollected reads , ultimately joining data \ntime points one large dataset.data collection template requires use new sheet spreadsheet\nweight collection time point, first sheet records\ninitial information animals. take weights three\ntime points, three time point sheets final file.\nConversely, collect weight data twenty time points, \ntwenty sheets final file. first function, called ``, reads data file, checks\nfind weight recording sheets, whether ’s three twenty, \nreads data sheets binds together single\ndataframe.remaining functions functions help track mouse \nexperiment even changes cages. processing data, key challenge\ntrack single mouse experiment. mice identified \npattern notches ears. However, limited number notches\ncan distinguished, notch information distinctly identify\nevery mouse study, just every mouse within certain cage. knowing\near notch ID cage number, can distinctly identify mouse\nstudy.However, mice moved one cage another cases study.\nmice within cage fighting, showing signs \nexcessive grooming, can reasons move mouse new cage \nexperiment started. cage moves need resolved \nprocessing data mouse can tracked even move.data collection template, created design aims include\ninformation cage moves, way simple \npossible person recording data. weights recorded \ntime point separate sheet data collection template. \nsheet time point, also columns give mouse’s cage \nstart data collection time point, well cage mouse \nmoved , moved. report template code uses information\ncreate unique ID mouse (one constant across \nexperiment), attach mouse’s measurements even mouse \nmoved one cage another. following two functions help \nprocess:Next, report template code gets workflow , uses\ncustom functions R code process data \nprovide summaries visualizations data.first step workflow read data spreadsheet.\nlong data collected following template described\nearlier, code able read correctly create \nmaster dataset data sheets spreadsheet. step\npipeline uses one custom functions defined start\nreport template code:Next, code runs number steps create unique ID \nmouse apply ID time point, even mouse\nchanges cages.Ultimately, creates unique ID mouse (column \ndataframe called mouse_id), well creates unique label can used\nplots tables (given mouse_label column). unique ID set \nbeginning study mouse remains throughout \nstudy. label, hand, based mouse’s ear notch pattern\nrecent cage recorded . made choice \nlabeling identifier, help researchers quickly identify \nmouse study based ’s current, rather starting, cage.next part code reads initial data recorded \nanimal experiment. code pulls information processed\nweights dataset match initial data animals unique ID.\nUltimately, starting data incorporated large dataset mouse\nweights, creating single large dataset work (our_mouse_weights) \nincludes information recorded data collection template.point, first rows large dataset look like :rest code report template create summaries graphs \ndata. First, code provides summaries research animals \nstart experiment. uses mouse_initial dataset (pulled\ndata first sheet data collection template). uses \nsummarize call summarize details sheet data, including \nspecies animal, total number animals, many males versus\nfemales, experimental groups included. uses additional\ncode format data resulting table clearer, \nuses kable function output results nicely formatted table.Table 3.1: Summary experimental animals start experimentThe next piece code creates time series mouse weights time. points\nmouse connected create line, ’s easy see variation\nacross mice single time point variation single mouse study.\nlines colored distinguish male female mouse (clear\ndifference average weights two groups). plot faceted \ntime series mice experimental group shown different small\n“facets” plot, axis ranges used small plot \nhelp comparisons across plots.Next, code creates boxplots focus differences weights \nlatest available timepoint. One boxplot created experimental\ngroup, points individual mice shown behind boxplot, \nprovide better idea pattern variation individual mice. \npoints colored based sex, help explore patterns sex.next piece code shows mouse weights vary person \nhandling animals certain time point. Different handlers may small\ndifferences handle weight mice. noticable\ndifferences measured weights, something corrected\nstatisical modeling later analysis, included potential\ncheck.next piece code creates table animals still\ntracked last time point (animals sacrificed prior last\nrecorded time point, included ). table focuses \nweight change since previous measured time point. ordered \nchange weight, largest decrease largest increase. meant\naide identifying mice showing signs suffering may need\nconsidered euthanized. animals labeled table \nrecent cage location, easier find necessary.\nexample code, ’ve shown sample 15 animals, report\nshow data animals.Table 3.2: Individual data weight changes mice current measurement previous measurement.last step, code template writes CSV file processed\ndata. file input script format data \nadd database collecting integrating data CSU\nexperiments, ultimately project-wide storage.","code":"\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(ggbeeswarm)\ncitation(\"readxl\")## \n## To cite package 'readxl' in publications use:\n## \n##   Hadley Wickham and Jennifer Bryan (2019). readxl: Read Excel Files. R\n##   package version 1.3.1. https://CRAN.R-project.org/package=readxl\n## \n## A BibTeX entry for LaTeX users is\n## \n##   @Manual{,\n##     title = {readxl: Read Excel Files},\n##     author = {Hadley Wickham and Jennifer Bryan},\n##     year = {2019},\n##     note = {R package version 1.3.1},\n##     url = {https://CRAN.R-project.org/package=readxl},\n##   }\n## Function to read in mouse weights. This takes a filepath to an Excel sheet\n## that follows the template of the animal weight collection template. It \n## identifies all the sheets in that file and reads in all the ones that \n## measure weekly weights. It returns one large dataframe with all of the \n## measured weights. \nread_mouse_weights <- function(filepath) {\n  \n  # getting info about all excel sheets\n  mouse_weights_sheets <- readxl::excel_sheets(filepath)[-1] # First sheet is initial data, not mouse weights\n  \n  mouse_weights <- purrr::map(mouse_weights_sheets, \n                              ~ readxl::read_excel(filepath, sheet = .x, \n                                                   col_types = c(\"text\",   # who_collected\n                                                                 \"text\",   # date_collected\n                                                                 \"text\",   # notch_id\n                                                                 \"numeric\", # weight\n                                                                 \"text\",   # unit\n                                                                 \"text\",   # existing_cage_number\n                                                                 \"text\",   # new_cage_number\n                                                                 \"text\",   # group\n                                                                 \"text\"    # notes\n                                                                 ))) %>% \n    dplyr::bind_rows() %>% \n    mutate(date_collected = lubridate::mdy(date_collected))\n\n  return(mouse_weights)\n}\n# Function to get the next cage number based on the \n# existing cage number and notch ID. If the mouse does not\n# switch cages again, the output is a vector of length 0. \n# This takes the dataframe and existing identifiers (notch id and\n# existing cage number) as inputs. It returns the next cage\n# that the mouse was moved to. If the mouse has not moved\n# from the existing case, the output has length 0.\nget_next_cage <- function(existing_cage_number, notch_id, \n                          df = our_mouse_weights){\n  next_cage <- df %>% \n    filter(.data$existing_cage_number == {{existing_cage_number}} &\n             .data$notch_id == {{notch_id}} & \n             !is.na(.data$new_cage_number)) %>% \n    pull(new_cage_number)\n  \n  return(next_cage)\n}\n\n# Function to get the full list of cages for each individual \n# mouse, over the course of all data collected to date. This \n# inputs the starting identifiers of the mouse (starting cage ID \n# and notch ID). It then works through any cage changes to create\n# a list for that mouse of all cages it was put in over the \n# course of the experiment. \nget_mouse_cages <- function(mouse_starting_cage, mouse_notch_id, \n                            df = our_mouse_weights){\n  mouse_cage_list <- mouse_starting_cage\n  i <- 1\n  \n  while(TRUE){\n    next_cage <- get_next_cage(existing_cage_number =\n                               mouse_cage_list[i],\n                               notch_id = mouse_notch_id, \n                               df = df)\n    if(length(next_cage) == 0) {\n      break\n      }\n    i <- i + 1\n    mouse_cage_list[i] <- next_cage\n    }\n  \n  return(mouse_cage_list)\n}\n# Read in the mouse weights from the Excel template. This creates one large\n# dataframe with the weights from all the timepoints. \nour_mouse_weights <- read_mouse_weights(filepath =\n                                          \"DATA/body_weights_measurement.xlsx\")\n# Add a unique mouse ID for the first time point. This will become each mouse's\n# unique ID across all measured timepoints.\nour_mouse_weights <- our_mouse_weights %>% \n  mutate(mouse_id = 1:n(), \n         mouse_id = ifelse(date_collected ==\n                                    first(date_collected), \n                                  mouse_id, \n                                  NA))\n\n# Create a dataframe that lists all mice at the first time point, \n# as well as a list of all the cages they have been in over the\n# experiment\nmice_cage_lists <- our_mouse_weights %>% \n  filter(date_collected == first(date_collected)) %>% \n  select(notch_id, existing_cage_number, mouse_id) %>% \n  mutate(cage_list = map2(.x = existing_cage_number, \n                          .y = notch_id, \n                          .f = ~ get_mouse_cages(.x, .y, df = our_mouse_weights)))\n\n# Add a column with the latest cage to the weight dataframe\nour_mouse_weights$latest_cage <- NA\n\n# Loop through all the individual mice, based on mice with a \n# measurement at the first time point. Add the unique ID for \n# each mouse, which will apply throughout the experiment. Also \n# add the most recent cage ID, so the mouse can be identified\n# by lab members based on it's current location\nfor(i in 1:nrow(mice_cage_lists)){\n  this_notch_id <- mice_cage_lists[i, ]$notch_id\n  this_cage_list <- mice_cage_lists[i, ]$cage_list[[1]]\n  this_unique_id <- mice_cage_lists[i, ]$mouse_id\n  latest_cage <- this_cage_list[length(this_cage_list)]\n  \n  our_mouse_weights$mouse_id[our_mouse_weights$notch_id == this_notch_id & \n                       our_mouse_weights$existing_cage_number %in% \n                       this_cage_list] <- this_unique_id\n  \n  our_mouse_weights$latest_cage[our_mouse_weights$notch_id == this_notch_id & \n                       our_mouse_weights$existing_cage_number %in% \n                       this_cage_list] <- latest_cage\n}\n\n# Add a label for each mouse based on its notch_id and latest cage\nour_mouse_weights <- our_mouse_weights %>% \n  mutate(mouse_label = paste(\"Cage:\", latest_cage, \n                             \"Notch:\", notch_id))\n# Read in the data from the original file with the initial animal \n# characteristics\nmouse_initial <- readxl::read_excel(\"DATA/body_weights_measurement.xlsx\", \n                                      sheet = 1, \n                                      col_types = c(\"text\", # notch_id\n                                                    \"text\", # starting_cage_number\n                                                    \"text\", # dob\n                                                    \"text\", # species\n                                                    \"text\", # sex\n                                                    \"text\" # group\n                                                    )) %>%\n  mutate(dob = lubridate::mdy(dob), \n         sex = forcats::as_factor(sex))\n\n# Figure out the starting cage for each mouse, so they can be incorporated\n# with the initial data so we can get the mouse ID that was added for the \n# starting time point\nmouse_ids <- our_mouse_weights %>% \n  filter(date_collected == first(date_collected)) %>% \n  select(notch_id, existing_cage_number, mouse_id) %>% \n  rename(starting_cage_number = existing_cage_number)\n\n# Merge in the mouse IDs with the dataframe of initial mouse characteristics\nmouse_initial <- mouse_initial %>% \n  left_join(mouse_ids, by = c(\"notch_id\", \"starting_cage_number\"))\n\n# Join the initial data with the weekly weights data into one large dataset\nour_mouse_weights <- our_mouse_weights %>% \n  left_join(mouse_initial, by = c(\"mouse_id\", \"notch_id\", \"group\"))\nour_mouse_weights %>% \n  slice(1:5)## # A tibble: 5 × 16\n##   who_collected date_collected notch_id weight unit  existing_cage_number\n##   <chr>         <date>         <chr>     <dbl> <chr> <chr>               \n## 1 Taru          2022-05-26     0          18.4 g     22003               \n## 2 Taru          2022-05-26     1R         17.2 g     22003               \n## 3 Taru          2022-05-26     1L         17   g     22003               \n## 4 Taru          2022-05-26     1R1L       18.8 g     22003               \n## 5 Taru          2022-05-26     0          18.4 g     22004               \n## # … with 10 more variables: new_cage_number <chr>, group <chr>, notes <chr>,\n## #   mouse_id <int>, latest_cage <chr>, mouse_label <chr>,\n## #   starting_cage_number <chr>, dob <date>, species <chr>, sex <fct>\n# Create a table that summarizes the animals at the start of the experiment\nmouse_initial %>% \n  summarize(Species = paste(unique(species), collapse = \", \"), \n            `Total animals` = n(), \n            `Sex distribution` = paste0(\"male: \", sum(sex == \"m\"), \n                                      \", female: \", sum(sex == \"f\")),\n            `Experimental groups` = paste(unique(group), collapse = \", \"),\n            `N. of starting cages` =\n              length(unique(starting_cage_number))) %>% \n  mutate_all(as.character) %>% \n  pivot_longer(everything()) %>% \n  mutate(name = paste0(name, \":\")) %>% \n  knitr::kable(col.names = c(\"\", \"\"), \n               caption = \"Summary of experimental animals at the start of the experiment\", \n               align = c(\"r\", \"l\"))\n# Create a plot of mouse weights over time\nour_mouse_weights %>% \n  ggplot(aes(x = date_collected, y = weight, \n             group = mouse_id, color = sex)) + \n  geom_line() + \n  facet_wrap(~ group) + \n  ggtitle(\"Animal weights over time by experiment group\") +\n  labs(x = \"Date collected\", \n       y = \"Weight (g)\")\n# Plot animal weight boxplots for the latest time point \nour_mouse_weights %>% \n  filter(date_collected == last(date_collected)) %>% \n  ggplot(aes(x = group, y = weight)) + \n  geom_beeswarm(aes(color = sex)) + \n  geom_boxplot(fill = NA, color = \"dodgerblue\") + \n  ggtitle(\"Animal weights at last collection by experimental group\") + \n  labs(x = \"Experimental group\", \n       y = \"Weight (g)\")\n# Plot animal weights by animal handler\nour_mouse_weights %>% \n  ggplot(aes(x = date_collected, y = weight, color = who_collected)) + \n  geom_point() + \n  ggtitle(\"Animal weights by animal handler\") + \n  labs(x = \"Date collected\", \n       y = \"Weight (g)\",\n       color = \"Person who\\nhandled the\\nanimal\")\n# Create table of animal weight changes since previous time point\nour_mouse_weights %>% \n  select(date_collected, weight, group, mouse_label, sex) %>% \n  group_by(mouse_label) %>% \n  mutate(weight_change = (weight - lag(weight)) / lag(weight)) %>% \n  ungroup() %>% \n  filter(date_collected == last(date_collected)) %>% \n  mutate(formatted_weight_change = paste0(formatC(weight_change * 100, \n                                                  digits = 1, format = \"f\"), \"%\")) %>% \n  arrange(weight_change) %>% \n  select(mouse_label, group, sex, weight, formatted_weight_change) %>% \n  slice(1:15) %>%  # Only for the chapter--show a sample, not all\n  knitr::kable(col.names = c(\"Mouse\", \"Experimental group\", \"Sex\", \n                             \"Weight (g)\", \"Weight change since last measure\"), \n               caption = \"Individual data on weight changes in mice between current measurement and previous measurement.\")\n# Write out processed data into a CSV file\nwrite_csv(our_mouse_weights, \"example_mouse_output.csv\")"},{"path":"colony-forming-units-to-determine-bacterial-counts.html","id":"colony-forming-units-to-determine-bacterial-counts","chapter":"4 Colony forming units to determine bacterial counts","heading":"4 Colony forming units to determine bacterial counts","text":"","code":""},{"path":"colony-forming-units-to-determine-bacterial-counts.html","id":"downloads-1","chapter":"4 Colony forming units to determine bacterial counts","heading":"4.0.1 Downloads","text":"downloads chapter :[Data collection template] recording colony forming units counted \nplate section plate laboratory[Report template] process data collected data template (go link, go “File” bar browser’s menu bar, chose “Save ,” save file “animal_weights.Rmd”)[Example output] report template","code":""},{"path":"colony-forming-units-to-determine-bacterial-counts.html","id":"overview-2","chapter":"4 Colony forming units to determine bacterial counts","heading":"4.0.2 Overview","text":"experiments, need estimate bacterial load \nMycobacterium tuberculosis organs—including lungs spleens—\nanimals experiments. measurements help us assess well vaccine\nworked comparison controls.estimating bacterial load animal organ using plate count\nmethod serial dilutions. Serial dilutions allow create \nhighly diluted sample without needing massive amount diluent: \nincrease dilution one step time, can steadily bring samples\nlower bacterial loads per volume. method common across\nlaboratories study tuberculosis drug efficacy method estimating\nbacterial load animal organs (Franzblau et al. 2012) \nwell-established method across microbiology general, dating back Koch \nlate 1800s (Wilson 1922; Ben-David Davidson 2014).method, homogenize part organ, create several\nincreasingly dilute samples. dilution spread plate \nmedium Mycobacterium tuberculosis can grow left grow \nseveral weeks temperature conducive Mycobacterium tuberculosis growth.\nidea individual bacteria original sample end randomly\nspread across surface plate, bacteria viable\n(able reproduce) form new colony , , ’ll able\nsee (Wilson 1922; Goldman Green 2015). end \nincubation period, can count number colony-forming units\n(CFUs) plate.count number CFUs, need “just right” dilution (\noften won’t know plating) countable\nplate. high dilution (.e., one viable\nbacteria), randomness play big role CFU count, ’ll estimate\noriginal variability, isn’t ideal. low\ndilution (.e., one lots viable bacteria), difficult \nidentify separate colonies, may compete resources. (pattern\nsee dilution low (.e., concentrated bacteria) \ncalled lawn—colonies merge together).identify good dilution sample, CFU count \ndilution can used estimate bacterial load animal’s organ. \ntranslate diluted concentration original concentration, \nback-calculation, incorporating number colonies counted \ndilution dilute sample (Ben-David Davidson 2014; Goldman Green 2015).","code":""},{"path":"colony-forming-units-to-determine-bacterial-counts.html","id":"template-description-1","chapter":"4 Colony forming units to determine bacterial counts","heading":"4.0.3 Template description","text":"data collected spreadsheet multiple sheets. first sheet\n(named “metadata”) used record metadata experiment, \nfollowing sheets used record CFUs counts plates used samples\norgan, one sheet per organ. example, plated data\nlung spleen, three sheets file: one\nmetadata, one plate counts lung, one \nplate counts spleen.first sheet, metadata sheet shown :metadata sheet used record information overall process \nplating data. Values sheet used calculating bacterial\nload original sample based CFU counts. spreadsheet includes\nfollowing columns:organ: Include one row organ plated experiment.\nname organ lowercase (e.g., “lung,” “spleen”). \nuse name also name sheet records data organ\nexample, rows metadata sheet “lung” “spleen,”\ntwo sheets file, one sheet named “lung” \none named “spleen,” ’ll use store plate counts \norgans.percentage_of_organ: column, give proportion organ \nplated. example, plated half lung, “lung” row\nspread sheet, put 0.5 prop_resuspended column.aliquot_ul: 100 uL total_resuspended slurry considered original aliquot used peform serial dilutions.dilution_factor: Amount original stock solution present \ntotal solution, dilution(s)total_resuspended_mL: column contains original volume tissue homogenate. example, raw lung tissue homogenized 0.5 mL PBS tube containing metal beads.volume_plated_ul: Amount suspension + diluent plated section solid agarFollowing first sheet file, one sheet \norgan. organs record sheets match rows\nfirst, metadata sheet template.organ-specific sheets look like :organ-specific sheets template include following columns:count_date: date CFUs counted. cases, plates\nmay counted multiple dates.who_plated: identifier researcher plated samplewho_counted: identifier researcher counted plate \nspecific dategroups: experimental group mouse belonged tomouse: identifier unique mouse within group (note: \ncollect data new experiment, can unique ID mouse, based \nnotch ID cage number)dil_0, dil_1, dil_2, …: count dilution. can add additional\ncolumns dilutions template take away\ndilution columns fewer. However, dilution columns \nnamed consistently, “dil_” followed dilution number (e.g., “0,” “1,”\n“2”). CFUs numerous count sample particular\ndilution, put “TNTC” cell spreadsheet.download template, example values filled blue.\nUse get idea record data. ready\nrecord data, delete example values replace \ndata collected experiment.","code":""},{"path":"colony-forming-units-to-determine-bacterial-counts.html","id":"processing-collected-data-1","chapter":"4 Colony forming units to determine bacterial counts","heading":"4.0.4 Processing collected data","text":"","code":""},{"path":"colony-forming-units-to-determine-bacterial-counts.html","id":"details-of-processing-script-1","chapter":"4 Colony forming units to determine bacterial counts","heading":"4.0.5 Details of processing script","text":"","code":""},{"path":"colony-forming-units-to-determine-bacterial-counts.html","id":"read-in-data","chapter":"4 Colony forming units to determine bacterial counts","heading":"4.1 Read in data","text":"","code":"\nlibrary(readxl)\nlibrary(dplyr)\nlibrary(purrr)\nlibrary(tidyr)\nlibrary(stringr)\nlibrary(tidyverse)\nlibrary(gridExtra)\nlibrary(ggplot2)\nlibrary(ggpubr)\n\n#Replace w/ path to CFU sheet\npath <- c(\"DATA/Copy of baa_cfu_sheet.xlsx\")\n\nsheet_names <- excel_sheets(path)\nsheet_names <- sheet_names[!sheet_names %in% c(\"metadata\")]\n\nmerged_data <- list()\n\nfor(i in 1:length(sheet_names)){\n  \n  data <- read_excel(path, sheet = sheet_names[i]) %>% \n    mutate(organ = paste0(sheet_names[i]))\n  \n  data <- data %>% \n    #mutate(missing_col = NA) %>% \n    mutate_if(is.double, as.numeric) %>% \n    mutate_if(is.numeric, as.character) %>% \n    pivot_longer(starts_with(\"dil_\"), names_to = \"dilution\",\n                 values_to = \"CFUs\") %>% \n    mutate(dilution = str_extract(dilution, \"[0-9]+\"),\n           dilution = as.numeric(dilution))\n    \n  \n  merged_data[[i]] <- data\n  \n  \n}\n  \nall_data <- bind_rows(merged_data, .id = \"column_label\") %>% \n    select(-column_label)\n  \nhead(merged_data)## [[1]]\n## # A tibble: 342 × 8\n##    count_date           who_plated who_counted groups mouse organ dilution CFUs \n##    <chr>                <chr>      <chr>       <chr>  <chr> <chr>    <dbl> <chr>\n##  1 \"\\\"February 21 2022… BK         BK          group… A     lung         0 TNTC \n##  2 \"\\\"February 21 2022… BK         BK          group… A     lung         1 TNTC \n##  3 \"\\\"February 21 2022… BK         BK          group… A     lung         2 TNTC \n##  4 \"\\\"February 21 2022… BK         BK          group… A     lung         3 53   \n##  5 \"\\\"February 21 2022… BK         BK          group… A     lung         4 9    \n##  6 \"\\\"February 21 2022… BK         BK          group… A     lung         5 4    \n##  7 \"\\\"February 21 2022… BK         BK          group… A     lung         6 2    \n##  8 \"\\\"February 21 2022… BK         BK          group… A     lung         7 1    \n##  9 \"\\\"February 21 2022… BK         BK          group… A     lung         8 0    \n## 10 \"\\\"February 21 2022… BK         BK          group… B     lung         0 TNTC \n## # … with 332 more rows\n## \n## [[2]]\n## # A tibble: 112 × 8\n##    count_date          who_plated who_counted groups  mouse organ dilution CFUs \n##    <chr>               <chr>      <chr>       <chr>   <chr> <chr>    <dbl> <chr>\n##  1 \"\\\"April 25 2022\\\"\" JR         JR          group_1 A     sple…        0 TNTC \n##  2 \"\\\"April 25 2022\\\"\" JR         JR          group_1 A     sple…        1 TNTC \n##  3 \"\\\"April 25 2022\\\"\" JR         JR          group_1 A     sple…        2 53   \n##  4 \"\\\"April 25 2022\\\"\" JR         JR          group_1 A     sple…        3 9    \n##  5 \"\\\"April 25 2022\\\"\" JR         JR          group_1 A     sple…        4 4    \n##  6 \"\\\"April 25 2022\\\"\" JR         JR          group_1 A     sple…        5 2    \n##  7 \"\\\"April 25 2022\\\"\" JR         JR          group_1 A     sple…        6 1    \n##  8 \"\\\"April 25 2022\\\"\" JR         JR          group_1 A     sple…        7 0    \n##  9 \"\\\"April 25 2022\\\"\" JR         JR          group_1 B     sple…        0 TNTC \n## 10 \"\\\"April 25 2022\\\"\" JR         JR          group_1 B     sple…        1 TNTC \n## # … with 102 more rows\nhead(all_data)## # A tibble: 6 × 8\n##   count_date            who_plated who_counted groups mouse organ dilution CFUs \n##   <chr>                 <chr>      <chr>       <chr>  <chr> <chr>    <dbl> <chr>\n## 1 \"\\\"February 21 2022\\… BK         BK          group… A     lung         0 TNTC \n## 2 \"\\\"February 21 2022\\… BK         BK          group… A     lung         1 TNTC \n## 3 \"\\\"February 21 2022\\… BK         BK          group… A     lung         2 TNTC \n## 4 \"\\\"February 21 2022\\… BK         BK          group… A     lung         3 53   \n## 5 \"\\\"February 21 2022\\… BK         BK          group… A     lung         4 9    \n## 6 \"\\\"February 21 2022\\… BK         BK          group… A     lung         5 4"},{"path":"colony-forming-units-to-determine-bacterial-counts.html","id":"example-one","chapter":"4 Colony forming units to determine bacterial counts","heading":"4.2 Example one","text":"","code":""},{"path":"colony-forming-units-to-determine-bacterial-counts.html","id":"exploratory-analysis-and-quality-checks","chapter":"4 Colony forming units to determine bacterial counts","heading":"4.3 Exploratory analysis and quality checks","text":"","code":""},{"path":"colony-forming-units-to-determine-bacterial-counts.html","id":"exploratory-analysis","chapter":"4 Colony forming units to determine bacterial counts","heading":"4.4 Exploratory analysis","text":"Dimensions input data:Based input data, data collected following organ \norgans:following number mice included :following number replicates recorded count date \nexperimental group:following number dilutions dilution level recorded \norgan:People plated collected data. Date dates counting:Based input data, plates included data counted \nfollowing person persons:\nBased input data, plates included data counted \nfollowing date dates:Distribution CFUs dilution:’s plot shows many plates numerous count \ndilution level:plot shows CFU counts distributed dilution\nlevel data:","code":"\nall_data %>%\n  select(organ, who_plated, who_counted, count_date) %>%\n  distinct()## # A tibble: 3 × 4\n##   organ  who_plated who_counted count_date            \n##   <chr>  <chr>      <chr>       <chr>                 \n## 1 lung   BK         BK          \"\\\"February 21 2022\\\"\"\n## 2 lung   BK         BK          \"\\\"April 18 2022\\\"\"   \n## 3 spleen JR         JR          \"\\\"April 25 2022\\\"\"\nhead(all_data)## # A tibble: 6 × 8\n##   count_date            who_plated who_counted groups mouse organ dilution CFUs \n##   <chr>                 <chr>      <chr>       <chr>  <chr> <chr>    <dbl> <chr>\n## 1 \"\\\"February 21 2022\\… BK         BK          group… A     lung         0 TNTC \n## 2 \"\\\"February 21 2022\\… BK         BK          group… A     lung         1 TNTC \n## 3 \"\\\"February 21 2022\\… BK         BK          group… A     lung         2 TNTC \n## 4 \"\\\"February 21 2022\\… BK         BK          group… A     lung         3 53   \n## 5 \"\\\"February 21 2022\\… BK         BK          group… A     lung         4 9    \n## 6 \"\\\"February 21 2022\\… BK         BK          group… A     lung         5 4"},{"path":"colony-forming-units-to-determine-bacterial-counts.html","id":"identify-a-good-dilution-for-each-sample","chapter":"4 Colony forming units to determine bacterial counts","heading":"4.5 Identify a good dilution for each sample","text":"","code":"\n# Make all_data into tidy data and filter for CFUs between 10-75\n  \ntidy_cfu_data <- all_data %>%\n  mutate(dilution = str_extract(dilution, \"[0-9]+\"),\n         dilution = as.numeric(dilution)) %>%\n  filter((CFUs >= 5 & CFUs <= 95) | groups == \"control\") %>%\n  mutate(CFUs = as.numeric(CFUs)) \n\n\nhead(tidy_cfu_data)## # A tibble: 6 × 8\n##   count_date            who_plated who_counted groups mouse organ dilution  CFUs\n##   <chr>                 <chr>      <chr>       <chr>  <chr> <chr>    <dbl> <dbl>\n## 1 \"\\\"February 21 2022\\… BK         BK          group… A     lung         3    53\n## 2 \"\\\"February 21 2022\\… BK         BK          group… A     lung         4     9\n## 3 \"\\\"February 21 2022\\… BK         BK          group… C     lung         5     8\n## 4 \"\\\"February 21 2022\\… BK         BK          group… D     lung         3    53\n## 5 \"\\\"February 21 2022\\… BK         BK          group… A     lung         2    92\n## 6 \"\\\"February 21 2022\\… BK         BK          group… A     lung         4     7"},{"path":"colony-forming-units-to-determine-bacterial-counts.html","id":"calculate-cfus-from-best-dilutionestimate-bacterial-load-for-each-sample-based-on-good-dilution","chapter":"4 Colony forming units to determine bacterial counts","heading":"4.6 Calculate CFUs from best dilution/Estimate bacterial load for each sample based on good dilution","text":"","code":"\n# Calculating CFU/ml for every qualifying replicate between 10-75 CFUs. Column binding by organ name to the metadata sheet via inner_join().\nmeta <- read_excel(path, sheet = \"metadata\")\n\ntidy_cfu_meta_joined <- inner_join(meta, tidy_cfu_data) %>%\n  group_by(groups) %>% \n  mutate(CFUs_per_ml = (CFUs * (dilution_factor^dilution) * \n                          (total_resuspension_mL/volume_plated_ul) * 1000)) %>%\n  select(organ, count_date, who_plated, who_counted, groups,  mouse, dilution,  \n         CFUs, CFUs_per_ml) %>% \n  ungroup()## Joining, by = \"organ\"\nhead(tidy_cfu_meta_joined)## # A tibble: 6 × 9\n##   organ count_date            who_plated who_counted groups mouse dilution  CFUs\n##   <chr> <chr>                 <chr>      <chr>       <chr>  <chr>    <dbl> <dbl>\n## 1 lung  \"\\\"February 21 2022\\… BK         BK          group… A            3    53\n## 2 lung  \"\\\"February 21 2022\\… BK         BK          group… A            4     9\n## 3 lung  \"\\\"February 21 2022\\… BK         BK          group… C            5     8\n## 4 lung  \"\\\"February 21 2022\\… BK         BK          group… D            3    53\n## 5 lung  \"\\\"February 21 2022\\… BK         BK          group… A            2    92\n## 6 lung  \"\\\"February 21 2022\\… BK         BK          group… A            4     7\n## # … with 1 more variable: CFUs_per_ml <dbl>"},{"path":"colony-forming-units-to-determine-bacterial-counts.html","id":"create-initial-report-information-for-these-data","chapter":"4 Colony forming units to determine bacterial counts","heading":"4.7 Create initial report information for these data","text":"","code":"\ntidy_lung_cfu_plot <- tidy_cfu_meta_joined %>%\n  filter(organ == \"lung\") %>%\n  mutate(group = fct_relevel(groups, \"group_1\", \"group_2\", \"group_3\", \"group_4\")) %>%\n  ggplot(aes(x = groups, y = log10(CFUs_per_ml), fill = groups))+\n  stat_boxplot( aes(x = groups, y = log10(CFUs_per_ml)), \n    geom='errorbar', linetype=1, width=0.5)+ \n  geom_boxplot(aes(group = groups), fill = NA, show.legend = FALSE, color = \"lightgrey\")+\n  geom_point(show.legend = FALSE)+\n  labs(title = paste0(\"CFUs in early infected mouse lung\"), x = \"Group\", y = \"log10(CFU/mL)\",\n       color = \"Group\")+\n  guides(shape = \"none\")+\n  theme_minimal()+\n  stat_compare_means(label = \"p.signif\", method = \"t.test\", ref.group = \"group_1\") + \n  scale_y_continuous(expand = c(0, 0), limits = c(0, 8))\n\ntidy_lung_cfu_plot"},{"path":"colony-forming-units-to-determine-bacterial-counts.html","id":"sample-anova","chapter":"4 Colony forming units to determine bacterial counts","heading":"4.8 Sample ANOVA","text":"","code":"\ncfu_stats <- tidy_cfu_meta_joined %>% \n  group_by(organ) %>%\n  nest() %>%\n  mutate(aov_result = map(data, ~aov(CFUs_per_ml ~ groups, data = .x)),\n         tukey_result = map(aov_result, TukeyHSD),\n         tidy_tukey = map(tukey_result, broom::tidy)) %>%\n  unnest(tidy_tukey, .drop = TRUE) %>%\n  separate(contrast, into = c(\"contrast1\", \"contrast2\"), sep = \"-\") %>%\n  select(-data, -aov_result, -tukey_result, -term, -null.value)# %>%## Warning: The `.drop` argument of `unnest()` is deprecated as of tidyr 1.0.0.\n## All list-columns are now preserved.\n## This warning is displayed once every 8 hours.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\n  # filter(adj.p.value <= 0.05)\n\ncfu_stats## # A tibble: 9 × 7\n## # Groups:   organ [2]\n##   organ  contrast1 contrast2 estimate conf.low conf.high adj.p.value\n##   <chr>  <chr>     <chr>        <dbl>    <dbl>     <dbl>       <dbl>\n## 1 lung   group_2   group_1    -60953. -138742.    16836.      0.171 \n## 2 lung   group_3   group_1    -63903. -135699.     7893.      0.0963\n## 3 lung   group_4   group_1    -26214. -102416.    49987.      0.793 \n## 4 lung   group_3   group_2     -2950.  -69900.    64000.      0.999 \n## 5 lung   group_4   group_2     34739.  -36915.   106393.      0.569 \n## 6 lung   group_4   group_3     37689.  -27410.   102787.      0.417 \n## 7 spleen group_2   group_1     -6565   -13529.      399.      0.0656\n## 8 spleen group_3   group_1     -7310   -13341.    -1279.      0.0178\n## 9 spleen group_3   group_2      -745.   -6776.     5286.      0.943"},{"path":"colony-forming-units-to-determine-bacterial-counts.html","id":"save-processed-data-to-database","chapter":"4 Colony forming units to determine bacterial counts","heading":"4.9 Save processed data to database","text":"","code":""},{"path":"colony-forming-units-to-determine-bacterial-counts.html","id":"example-two","chapter":"4 Colony forming units to determine bacterial counts","heading":"4.10 Example two","text":"","code":""},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"enzyme-linked-immunosorbest-assay-elisa","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5 Enzyme-linked immunosorbest assay (ELISA)","text":"ELISA standard molecular biology assay detecting quantifying \nvariety compounds, including peptides, proteins, antibodies sample.\nsample serum, plasma, bronchoalveolar lavage fluid (BALF).","code":""},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"importance-of-elisa","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.1 Importance of ELISA","text":"antigen-specific reaction host results production antibodies, proteins found blood. event infectious disease,\naids detection antibodies body. ELISA distinguishable antibody-assays produces quantifiable findings separates non-specific specific interactions serial binding solid surfaces,\noften polystyrene multi-well plate.IMPAc-TB project, crucial evaluate vaccine eliciting humoral immunity generating antibodies vaccine antigen. ELISA \nused determine presence Immunoglobulin (Ig) IgG, IgA, IgM \nserum different time points post-vaccination.","code":""},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"principle-of-elisa","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.1.1 Principle of ELISA","text":"ELISA based principle antigen-antibody interaction. antigen must immobilized solid surface complexed enzyme-linked antibody ELISA. conjugated enzyme’s activity evaluated incubating substrate yield quantifiable result, enables detection. four basic steps ELISA:1. Coating multiwell plate antigen/antibody: step depends want detect sample. need evaluate presence antibody, plate coated antigen, vice versa. coat plate, fixed concentration antigen (protein) added 96 well high-binding plate (charged plate). Plate incubated night antigen 4 degree celsius (proteins temperature sensitive) antigens completely bound well.2. Blocking: possible every site well coated targeted antigen, uncovered areas. important block empty spaces primary antibody (add next step) binds spaces give us false positive results. , microplate well surface-binding sites blocked unrelated protein substance.common blocking agents bovine serum albumin, skim milk, casein. One best blocking agents use serum organism secondary (detection antibody) raised. example, secondary antibody raised goat, can use goat serum blocking agent.3. Probing: Probing step add sample containing antibodies want detect. primary antibody. antibodies antigen (coated) present sample, bind antigen high affinity.4. Washing: incubation sample containing primary antibody, wells washed unbound antibody washed away. Washing solution contains phosphate buffer saline + 0.05% tween-20 (mild detergent). 0.05% tween-20 washes away non-specific interactions strong, keeps specific interaction strong detached mild detergent.5. Detection: detect presence antibody-antigen complex, secondary antibody labelled enzyme (usually horseradish peroxidase) added wells, incubated washed.6. Signal Measurement: Finally detect “” “much” antibody present, chromogenic substrate (like 3,3’,5,5’-Tetramethylbenzidine) added wells, can cleaved enzyme tagged secondary antibody. color compund formed addition substrate, directly proportional amount antibody present sample. plate read plate reader, color converted numbers.\nFigure 5.1: caption\n","code":""},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"loading-libraries","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.1.2 Loading libraries","text":"","code":"\nlibrary(readxl)\nlibrary(tidyverse)\nlibrary(minpack.lm)\nlibrary(broom)\nlibrary(purrr)\nlibrary(ggbeeswarm)"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"elisa-data-analysis","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.2 ELISA data analysis","text":"Analysis ELISA data important part ELISA experiment. ELISA data can analyzed different ways based data acquired. examples type ELISA data :1. standard curve: ELISA can used determine concentrations antigen antibody. type ELISA data usually standard curve \ndifferent concentrations known analyte concentration sample determined extrapolating unknown values curve. type assay straightforward, easy interpret robust.2. Without standard curve: Usually vaccine studies involve investigating presence high-affinity (novel) antibodies vaccine antigens.\nTherefore, plotting standard curve feasible previous information available antibody concentration type antibody. Also, antibody response vaccine differ depending individual,\npractical generate calibration curve absolute concentrations can extrapolated.\ntype ELISA, quantification antibody titers performed using serial dilutions test samples, analysis can performed using following three methods (Hartman et al. 2018):Fitting sigmoid modelEndpoint titer method\n3: Absorbance summation methodLet’s look methods, can apply methods data, R-based packages can utilize perform analysis.","code":""},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"curve-fitting-model","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.3 1. Curve fitting model:","text":"curve ELISA data represents plot known concentrations versus corresponding signal responses. typical range calibration curves one two orders magnitude response axis two orders magnitude concentration axis. real curve assay easily identified infinite number concentration dilutions infinite number repetitions tested. correct curve must approximated relatively small number noisy points, though, finite number dilutions may performed. estimate dose-response relationship standard dilutions, method interpolating standards required standard every concentration. process typically performed using mathematical function regression approximate true shape curve. curve model name given approximating function, commonly uses two parameters describe family curves, adjusted order find curve family curves best fits assay data.Three qualities included good curve fitting model.\n1. true curve’s shape must accurately approximated curve model. curve model accomplish , way adjust component total error results lack fit.\n2. order get concentration estimates minimal inaccuracy, decent curve model must able average away much random variation practical. 3. successful curve model must capable accurately predicting concentration values points anchor points standard dilutions.","code":""},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"how-do-we-perform-curve-fitting-model","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.3.1 How do we perform curve fitting model","text":"two major steps performing curve fitting model non-linear data like ELISA:\n1. Finding initial starting estimates parameters\n2. locating optimal solution region initial estimatesWe presented example performed 8-10 point serial dilution sample fitted 4 parameter curve model.","code":""},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"an-example-of-the-curve-fitting-model","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.3.2 An example of the curve fitting model","text":"","code":""},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"read-in-the-data","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.3.2.1 Read in the data","text":"information comes 2018 study conducted Hartman et al. Hartman et al. analyzed ELISA data study utilizing fitted sigmoid analysis, end point titer, absorbance summation. utilized information determine whether formulas calculations provide outcomes values .","code":"\nelisa_example_data <- read_excel(\"DATA/example_elisa_data.xlsx\")"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"tidying-the-data","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.3.2.2 Tidying the data","text":"next performed tidying data make format can plot sigmoid curve .","code":"\n# Divide dilution column into two seoparate columns\n\nelisa_example_data <- separate(elisa_example_data, \n                               col = \"dilution\", \n                               into = c(\"numerator\", \"denominator\"), \n                               sep = \"\\\\/\")\n\n# Convert the tabke from character to numeric\nelisa_example_data <- elisa_example_data %>% \n  mutate_if(is.character, as.numeric)\n\n\nelisa_example_data$dilution <- \n  elisa_example_data$numerator/elisa_example_data$denominator  \n\nelisa_example_data <- elisa_example_data %>%\n  mutate(log_dilution = log(dilution, base = 3))\n\nhead(elisa_example_data)## # A tibble: 6 × 5\n##   numerator denominator absorbance dilution log_dilution\n##       <dbl>       <dbl>      <dbl>    <dbl>        <dbl>\n## 1         1          30       4    0.0333          -3.10\n## 2         1          90       3.73 0.0111          -4.10\n## 3         1         270       2.34 0.00370         -5.10\n## 4         1         810       1.1  0.00123         -6.10\n## 5         1        2430       0.51 0.000412        -7.10\n## 6         1        7290       0.22 0.000137        -8.10"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"create-function-for-curve-fitting-model","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.3.2.3 Create function for curve fitting model","text":"next created curve fitting model function using nlsLM function “minpack.lm” package.\npurpose nlslm minimize sum square vector returned function fn, modification Levenberg-Marquardt algorithm. early 1960s, Levenberg-Marquardt algorithm developed address nonlinear least squares problems. series well-chosen updates model parameter values, Levenberg-Marquardt algorithm lower sum squares errors model function data points.","code":"\nmod_1 <- nlsLM(absorbance ~ \n                 ((a-d)/(1+(log_dilution/c)^b)) + d,\ndata = elisa_example_data, \nstart = list (a = 4, d= 0, c = -5, b = 1))\n\n# a = maximum absorbance\n# d = minimum absobance\n# c = point of maximum growth \n# b = slope at c\n\nmod_1## Nonlinear regression model\n##   model: absorbance ~ ((a - d)/(1 + (log_dilution/c)^b)) + d\n##    data: elisa_example_data\n##        a        d        c        b \n##  4.12406  0.04532 -5.31056  7.62972 \n##  residual sum-of-squares: 0.02221\n## \n## Number of iterations to convergence: 9 \n## Achieved convergence tolerance: 1.49e-08\nsummary(mod_1)## \n## Formula: absorbance ~ ((a - d)/(1 + (log_dilution/c)^b)) + d\n## \n## Parameters:\n##   Estimate Std. Error  t value Pr(>|t|)    \n## a  4.12406    0.05820   70.860 1.75e-12 ***\n## d  0.04532    0.02268    1.998   0.0808 .  \n## c -5.31056    0.03933 -135.037 1.01e-14 ***\n## b  7.62972    0.35854   21.280 2.50e-08 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 0.05269 on 8 degrees of freedom\n## \n## Number of iterations to convergence: 9 \n## Achieved convergence tolerance: 1.49e-08"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"apply-the-function-to-the-data","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.3.2.4 Apply the function to the data","text":"","code":"\ntidy_params <- mod_1 %>% tidy() \n\na <- tidy_params$estimate[tidy_params$term == \"a\"]\nb <- tidy_params$estimate[tidy_params$term == \"b\"]\nc <- tidy_params$estimate[tidy_params$term == \"c\"]\nd <- tidy_params$estimate[tidy_params$term == \"d\"]\n\nelisa_example_data <- elisa_example_data %>%\n  mutate(fitted = predict(mod_1))\n\nelisa_example_data <- elisa_example_data %>%\n  mutate(fitted = predict(mod_1))"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"plot-the-sigmoid-curve-with-fitted-sigmoid-model","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.3.2.5 Plot the sigmoid curve with fitted sigmoid model","text":"","code":"\nelisa_example_data %>%\n  ggplot(aes(x = log_dilution, y = absorbance)) +\n  geom_point() +\n  geom_line(aes(y=fitted), color = \"dodgerblue\")"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"endpoint-titer-method","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.4 2. Endpoint titer method","text":"endpoint titer approach chooses absorbance value just background noise (lower asymptotic level). highest dilution absorbance greater predetermined value endpoint titer. method based assumption sample higher protein concentration require higher dilution factor achieve absorbance just level background noise.","code":""},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"create-an-endpoint-titer-function-and-apply-it-to-the-output-of-the-fitted-sigmoid-model-values.","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.4.1 Create an endpoint titer function and apply it to the output of the fitted sigmoid model values.","text":"","code":"\nendpoint_titer <- c * (((a - d) / (0.2 - d)) - 1) ^ (1 / b)\n\nsummary(endpoint_titer)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  -8.113  -8.113  -8.113  -8.113  -8.113  -8.113\nendpoint_titer## [1] -8.113285"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"other-methods-to-analyze-elisa-data","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.4.2 Other methods to analyze ELISA data","text":"","code":""},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"absorption-summation","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.4.2.1 Absorption summation","text":"","code":""},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"area-under-the-curve","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.4.2.2 Area under the curve","text":"model data analysis, sum absorbance values sample obtain one value. value termed absorption summation (). Using data, calculated :","code":"\nAS = 0.04 + 0.04 + 0.05 + 0.05 + 0.06 + \n  0.1 + 0.22 + 0.51 + 1.1 + 2.34 + 3.73 + 4.0\n\nAS## [1] 12.24"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"apply-the-fitting-sigmoid-model-and-endpoint-titer-function-in-our-dataset","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.5 Apply the fitting sigmoid model and endpoint titer function in our dataset","text":"presented data mouse study. data, presence IgG antibody evaluated receptor binding domain (RBD) SARS-CoV-2 virus two different groups mice. need elucidate group higher concentration antibodies.","code":""},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"read-in-the-data-1","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.5.0.1 Read in the data","text":"","code":"\nelisa_data <- read_excel(\"DATA/elisa_data_serial_dilution.xlsx\")"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"tidy-the-data","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.5.0.2 Tidy the data","text":"","code":"\nelisa_data <- pivot_longer(data = elisa_data, \n                           cols = \"Mouse_1\":\"Mouse_5\", \n                           names_to = \"mouse_id\", \n                           values_to = \"absorbance\")\n\nhead(elisa_data)## # A tibble: 6 × 4\n##   Groups  Dilution mouse_id absorbance\n##   <chr>   <chr>    <chr>         <dbl>\n## 1 Group 1 1/50     Mouse_1         4.1\n## 2 Group 1 1/50     Mouse_2         3.9\n## 3 Group 1 1/50     Mouse_3         4.3\n## 4 Group 1 1/50     Mouse_4         4.2\n## 5 Group 1 1/50     Mouse_5         4  \n## 6 Group 1 1/100    Mouse_1         3.9\n# separate dilution column and convert it to log2\n\nelisa_data <- separate(elisa_data, \n                       col = \"Dilution\", \n                       into = c(\"numerator\", \n                                \"denomenator\"), \n                       sep = \"\\\\/\")\n\nelisa_data <- elisa_data %>% \n  transform(numerator = as.numeric(numerator),\n            denomenator = as.numeric(denomenator))\n\nelisa_data <- elisa_data %>%\n  mutate(dilution = \n           elisa_data$numerator/elisa_data$denomenator) \n\nelisa_data <- elisa_data %>%\n  mutate(log_dilution = log2(dilution))\n\nhead(elisa_data)##    Groups numerator denomenator mouse_id absorbance dilution log_dilution\n## 1 Group 1         1          50  Mouse_1        4.1     0.02    -5.643856\n## 2 Group 1         1          50  Mouse_2        3.9     0.02    -5.643856\n## 3 Group 1         1          50  Mouse_3        4.3     0.02    -5.643856\n## 4 Group 1         1          50  Mouse_4        4.2     0.02    -5.643856\n## 5 Group 1         1          50  Mouse_5        4.0     0.02    -5.643856\n## 6 Group 1         1         100  Mouse_1        3.9     0.01    -6.643856"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"converting-data-into-dataframe","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.5.0.2.1 converting data into dataframe","text":"","code":"\nelisa_data_df <- elisa_data %>% \n  group_by(Groups, mouse_id) %>% \n  summarize(log_dilution = log_dilution, \n            absorbance = absorbance)## `summarise()` has grouped output by 'Groups', 'mouse_id'. You can override using\n## the `.groups` argument.\nelisa_data_nested <- elisa_data %>%\n  group_by(Groups, mouse_id) %>%\n  nest()\n\nhead(elisa_data_nested)## # A tibble: 6 × 3\n## # Groups:   Groups, mouse_id [6]\n##   Groups  mouse_id data             \n##   <chr>   <chr>    <list>           \n## 1 Group 1 Mouse_1  <tibble [10 × 5]>\n## 2 Group 1 Mouse_2  <tibble [10 × 5]>\n## 3 Group 1 Mouse_3  <tibble [10 × 5]>\n## 4 Group 1 Mouse_4  <tibble [10 × 5]>\n## 5 Group 1 Mouse_5  <tibble [10 × 5]>\n## 6 Group 2 Mouse_1  <tibble [10 × 5]>"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"plot-the-curves-to-evaluate-the-a-d-c-and-b","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.5.0.2.2 plot the curves to evaluate the a, d, c, and b","text":"Based curve, values := 4,\nd = 0\nc = 2\nb = 1","code":"\nelisa_data %>%\n  ggplot(aes(x = log_dilution, y = absorbance)) +\n  geom_point() +\n  geom_line() + \n  facet_wrap(Groups ~ mouse_id)"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"creating-a-function-for-fitting-model","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.5.1 Creating a function for fitting model","text":"","code":"\nfitted_model_elisa <- function(df_elisa, \n                               start_a, start_d, \n                               start_c, start_b) {\n  mod_1 <- nlsLM(absorbance ~ \n                   ((a-d)/(1+(log_dilution/c)^b)) + d,\ndata = df_elisa,\nstart = list(a = start_a, d = start_d, c = start_c, b = start_b))\n  return(mod_1)\n}"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"fitting-the-model-into-the-dataset","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.5.1.1 Fitting the model into the dataset","text":"","code":"\nfitted_model_elisa(elisa_data_nested$data[[1]], \n                   start_a = 4, \n                   start_d = 0, \n                   start_c = -8, \n                   start_b = 1)## Nonlinear regression model\n##   model: absorbance ~ ((a - d)/(1 + (log_dilution/c)^b)) + d\n##    data: df_elisa\n##        a        d        c        b \n##   4.3070  -0.6009 -10.2577   5.2893 \n##  residual sum-of-squares: 0.1199\n## \n## Number of iterations to convergence: 7 \n## Achieved convergence tolerance: 1.49e-08"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"apply-the-fitted-model-function-to-the-whole-dataframe","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.5.1.2 Apply the fitted model function to the whole dataframe","text":"","code":"\nelisa_fitted_data <- elisa_data_nested %>%\n  mutate(fitted_data = \n           purrr::map(data, ~ \n                        fitted_model_elisa(.x,start_a = 4, \n                                              start_d = 0, \n                                              start_c = -8, \n                                              start_b = 1)))\n\nhead(elisa_fitted_data)## # A tibble: 6 × 4\n## # Groups:   Groups, mouse_id [6]\n##   Groups  mouse_id data              fitted_data\n##   <chr>   <chr>    <list>            <list>     \n## 1 Group 1 Mouse_1  <tibble [10 × 5]> <nls>      \n## 2 Group 1 Mouse_2  <tibble [10 × 5]> <nls>      \n## 3 Group 1 Mouse_3  <tibble [10 × 5]> <nls>      \n## 4 Group 1 Mouse_4  <tibble [10 × 5]> <nls>      \n## 5 Group 1 Mouse_5  <tibble [10 × 5]> <nls>      \n## 6 Group 2 Mouse_1  <tibble [10 × 5]> <nls>"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"take-out-the-summary-of-the-data","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.5.1.3 Take out the summary of the data","text":"","code":"\nelisa_fitted_data_summary <- elisa_fitted_data %>%\n  mutate(elisa_fitted_data_summary = \n           purrr::map(fitted_data, broom::glance))\n\nunnested <- elisa_fitted_data_summary %>%\nunnest(elisa_fitted_data_summary) %>%\nungroup() %>%\ndplyr::select(Groups, mouse_id, fitted_data)\n\nunnested$fitted_data[[1]]## Nonlinear regression model\n##   model: absorbance ~ ((a - d)/(1 + (log_dilution/c)^b)) + d\n##    data: df_elisa\n##        a        d        c        b \n##   4.3070  -0.6009 -10.2577   5.2893 \n##  residual sum-of-squares: 0.1199\n## \n## Number of iterations to convergence: 7 \n## Achieved convergence tolerance: 1.49e-08"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"create-function-of-fitted-model-and-endpoint-titer-where-the-output-of-the-fitted-model-data-will-be-the-input-of-the-endpoint-titer","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.6 Create function of Fitted model and endpoint titer, where the output of the fitted model data will be the input of the endpoint titer","text":"","code":"\n# Fitted model function\nfitted_model_elisa <- function(df_elisa, \n                               start_a, \n                               start_d, \n                               start_c, \n                               start_b) {\n  mod_1 <- nlsLM(absorbance ~ \n                   ((a-d)/(1+(log_dilution/c)^b)) + d,\ndata = df_elisa,\nstart = list(a = start_a, d = start_d, c = start_c, b = start_b))\n  return(mod_1)\n}\n\n# Endpoint titer function\n\nendpoint_titer_elisa <- function(fitted_data, back_value) {\n  tidy_fitted <- broom::tidy(fitted_data)\n  est_a <- tidy_fitted$estimate[tidy_fitted$term == \"a\"]\n  est_b <- tidy_fitted$estimate[tidy_fitted$term == \"b\"]\n  est_c <- tidy_fitted$estimate[tidy_fitted$term == \"c\"]\n  est_d <- tidy_fitted$estimate[tidy_fitted$term == \"d\"]\n  endpoint_titer <- est_c * (((est_a - est_d) / (back_value - est_d)) - 1) ^ (1 / est_b)\n  return(endpoint_titer)\n}"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"apply-the-fitted-model-fuction-into-the-nested-data-and-use-the-output-of-the-fitted-data-as-the-input-for-endpoint-titer-value-evaluation","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.6.0.1 Apply the fitted model fuction into the nested data and use the output of the fitted data as the input for endpoint titer value evaluation","text":"","code":""},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"run-fitted-model-on-the-data","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.6.0.1.1 Run fitted model on the data","text":"","code":"\nelisa_data_with_fit_model <- elisa_data_nested %>%\n  mutate(fitted_data = purrr::map(data, \n                                  ~ fitted_model_elisa(.x, start_a = 4, \n                                                          start_d = 0, \n                                                          start_c = -8, \n                                                          start_b = 1)))\n\nhead(elisa_data_with_fit_model)## # A tibble: 6 × 4\n## # Groups:   Groups, mouse_id [6]\n##   Groups  mouse_id data              fitted_data\n##   <chr>   <chr>    <list>            <list>     \n## 1 Group 1 Mouse_1  <tibble [10 × 5]> <nls>      \n## 2 Group 1 Mouse_2  <tibble [10 × 5]> <nls>      \n## 3 Group 1 Mouse_3  <tibble [10 × 5]> <nls>      \n## 4 Group 1 Mouse_4  <tibble [10 × 5]> <nls>      \n## 5 Group 1 Mouse_5  <tibble [10 × 5]> <nls>      \n## 6 Group 2 Mouse_1  <tibble [10 × 5]> <nls>"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"taking-output-of-the-fitted-model-function-and-into-endpoint-titer-function","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.6.0.1.2 Taking output of the fitted model function and into endpoint titer function","text":"","code":"\nelisa_data_with_endpoint_titer <- elisa_data_with_fit_model %>%\n  mutate(endpoint_data = \n           purrr::map(fitted_data, \n                      ~ endpoint_titer_elisa(.x, back_value = 0.2)))"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"plot-the-endpoint-titer-data-for-the-two-groups","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.6.0.2 Plot the endpoint titer data for the two groups","text":"","code":"\nelisa_data_with_endpoint_titer$endpoint_data=\n  as.numeric(elisa_data_with_endpoint_titer$endpoint_data)\n\nelisa_data_with_endpoint_titer %>%\n  ggplot(aes(x = Groups, y = endpoint_data, color = Groups)) +\n geom_beeswarm(cex = 3) "},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"perform-statistical-analysis-on-the-data","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.6.0.3 Perform statistical analysis on the data","text":"","code":"\nelisa_data_stats <- t.test(endpoint_data ~ Groups, \n                           data = elisa_data_with_endpoint_titer)\n\nelisa_data_stats %>%\n  tidy()## # A tibble: 1 × 10\n##   estimate estimate1 estimate2 statistic    p.value parameter conf.low conf.high\n##      <dbl>     <dbl>     <dbl>     <dbl>      <dbl>     <dbl>    <dbl>     <dbl>\n## 1   -0.800     -14.0     -13.2     -18.8 0.00000268      5.63   -0.906    -0.695\n## # … with 2 more variables: method <chr>, alternative <chr>"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"statistical-data-analysis-for-more-than-two-groups","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.6.0.4 Statistical data analysis for more than two groups","text":"","code":""},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"elisa-data-processing","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.7 ELISA data processing","text":"read ELISA plate 96 well plate using plate reader. plate reader generates data form number excel sheet. created pipeline/worksheet bring information excl sheet tidy format created fitted model endpoint titer functions can applied.","code":""},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"read-in-the-first-dataset","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.7.0.1 Read in the first dataset","text":"example ELISA data came straight plate reader. data arranged 96-well plate format contains Optical Density (OD) values.","code":"\nelisa_raw_data <- read_excel(\"DATA/elisa_s1_07-25-20.xlsx\", \n                             sheet = \"S1\", col_names = FALSE,  \n                             range = \"B2:M9\")## New names:\n## * `` -> ...1\n## * `` -> ...2\n## * `` -> ...3\n## * `` -> ...4\n## * `` -> ...5\n## * ...\nhead(elisa_raw_data)## # A tibble: 6 × 12\n##   ...1          ...2  ...3 ...4   ...5  ...6 ...7   ...8  ...9 ...10 ...11 ...12\n##   <chr>        <dbl> <dbl> <chr> <dbl> <dbl> <chr> <dbl> <dbl> <chr> <dbl> <dbl>\n## 1 5.199999999… 0.05  0.069 6.3E… 0.061 0.122 0.16… 0.145 0.135 6.80… 0.053 0.05 \n## 2 7.900000000… 0.098 0.069 6.80… 0.115 0.202 5.89… 0.134 0.069 0.106 0.05  0.075\n## 3 8.899999999… 0.133 0.119 OVRF… 3.87  2.32  OVRF… 3.85  2.12  OVRF… 3.21  1.02 \n## 4 OVRFLW       3.46  1.16  OVRF… 3.80  2.36  OVRF… 3.70  1.49  OVRF… 3.68  1.63 \n## 5 3.815999999… 1.82  0.446 3.89… 3.42  1.13  OVRF… 2.33  0.608 OVRF… 3.41  1.10 \n## 6 OVRFLW       3.69  1.43  OVRF… 3.66  1.27  3.839 1.74  0.444 2.49… 0.637 0.704"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"tidy-dataset-1","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.7.0.2 Tidy dataset 1","text":"important clean data arrange format can apply formulas functions.","code":"\n# Convert all columns to numeric\n\nelisa_raw_data_numeric <- elisa_raw_data %>% \n  mutate_if(is.character, as.numeric)## Warning in mask$eval_all_mutate(quo): NAs introduced by coercion\n\n## Warning in mask$eval_all_mutate(quo): NAs introduced by coercion\n\n## Warning in mask$eval_all_mutate(quo): NAs introduced by coercion\n\n## Warning in mask$eval_all_mutate(quo): NAs introduced by coercion\n# pivot longer the data\n\nelisa_raw_data_tidy <- pivot_longer(data = elisa_raw_data_numeric, cols = \"...1\":\"...12\", names_to = \"well_id\", values_to = \"od_450nm\")\n\n# remove \"...\" from the first column\n\nelisa_raw_data_tidy$well_id <- str_replace(elisa_raw_data_tidy$well_id, \"...\", \"\")\n\n# Add new column to the data_frame\n\nelisa_raw_data_tidy_new <- elisa_raw_data_tidy %>%\n  mutate(name = rep(LETTERS[1:8], each = 12))\n\nelisa_raw_data_tidy_new <- elisa_raw_data_tidy_new %>%\n  mutate(well_id = paste0(name, well_id)) %>%\n  select(-name)\n\nhead(elisa_raw_data_tidy_new)## # A tibble: 6 × 2\n##   well_id od_450nm\n##   <chr>      <dbl>\n## 1 A1         0.052\n## 2 A2         0.05 \n## 3 A3         0.069\n## 4 A4         0.063\n## 5 A5         0.061\n## 6 A6         0.122"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"read-in-the-second-data-set","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.7.0.3 Read in the second data set","text":"second dataset contains information groups, mouse id, dilutions respective wells 96 well plate dataset-1.","code":"\nelisa_label_data <- read_excel(\"DATA/elisa_s1_07-25-20.xlsx\", \n                               sheet = \"S1\", col_names = FALSE,  \n                               range = \"Q2:AB9\")## New names:\n## * `` -> ...1\n## * `` -> ...2\n## * `` -> ...3\n## * `` -> ...4\n## * `` -> ...5\n## * ...\nhead(elisa_label_data)## # A tibble: 6 × 12\n##   ...1        ...2   ...3  ...4  ...5  ...6  ...7  ...8  ...9  ...10 ...11 ...12\n##   <chr>       <chr>  <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr> <chr>\n## 1 blank       secon… naïv… 1A-1… 1A-1… 1A-1… 1A-2… 1A-2… 1A-2… 1A-3… 1A-3… 1A-3…\n## 2 1A-4 (1/250 1A-4 … 1A-4… 1B-1… 1B-1… 1B-1… 1B-2… 1B-2… 1B-2… 1B-3… 1B-3… 1B-3…\n## 3 1B-4 (1/250 1B-4 … 1B-4… 2A-1… 2A-1… 2A-1… 2A-2… 2A-2… 2A-2… 2A-3… 2A-3… 2A-3…\n## 4 2B-1 (1/250 2B-1 … 2B-1… 2B-2… 2B-2… 2B-2… 2B-3… 2B-3… 2B-3… 2B-4… 2B-4… 2B-4…\n## 5 3A-1 (1/250 3A-1 … 3A-1… 3A-2… 3A-2… 3A-2… 3A-3… 3A-3… 3A-3… 3A-4… 3A-4… 3A-4…\n## 6 3B-1 (1/250 3B-1 … 3B-1… 3B-2… 3B-2… 3B-2… 3B-3… 3B-3… 3B-3… 3B-4… 3B-4… 3B-4…"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"tidy-dataset-2","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.7.0.4 Tidy dataset-2","text":"","code":"\n# pivot longer the data\n\nelisa_label_data_tidy <- pivot_longer(data = elisa_label_data, \n                                      cols = \"...1\":\"...12\", \n                                      names_to = \"well_id\", \n                                      values_to = \"information\")\n\n# remove \"...\" from the first column\n\nelisa_label_data_tidy$well_id <- str_replace(elisa_label_data_tidy$well_id, \"...\", \"\")\n\n# Add new column to the data_frame\n\nelisa_label_data_tidy_new <- elisa_label_data_tidy %>%\n  mutate(name = rep(LETTERS[1:8], each = 12))\n\nelisa_label_data_tidy_new <- elisa_label_data_tidy_new %>%\n  mutate(well_id = paste0(name, well_id)) %>%\n  select(-name)\n\nhead(elisa_label_data_tidy_new)## # A tibble: 6 × 2\n##   well_id information  \n##   <chr>   <chr>        \n## 1 A1      blank        \n## 2 A2      secondary    \n## 3 A3      naïve (1/250)\n## 4 A4      1A-1 (1/250  \n## 5 A5      1A-1 (1/1250 \n## 6 A6      1A-1 (1/6250"},{"path":"enzyme-linked-immunosorbest-assay-elisa.html","id":"merge-dataset-1-with-od-information-with-dataset-2-with-respective-data-information","chapter":"5 Enzyme-linked immunosorbest assay (ELISA)","heading":"5.7.0.5 Merge dataset-1 (with OD information) with dataset-2 (with respective data information)","text":"create complete full dataset Groups, mouse-id, dilutions, OD, merged dataset-1 dataset-2 together. also cleaned data set mouse-ID dilution columns separate columns.","code":"\n#Merge the two datasets\n\nelisa_data = elisa_raw_data_tidy_new %>% inner_join(elisa_label_data_tidy_new,\n                                                    by=\"well_id\")\n\nhead(elisa_data)## # A tibble: 6 × 3\n##   well_id od_450nm information  \n##   <chr>      <dbl> <chr>        \n## 1 A1         0.052 blank        \n## 2 A2         0.05  secondary    \n## 3 A3         0.069 naïve (1/250)\n## 4 A4         0.063 1A-1 (1/250  \n## 5 A5         0.061 1A-1 (1/1250 \n## 6 A6         0.122 1A-1 (1/6250\n### Separate the information table into sample ID and dilution columns\n\ntidy_elisa_data <- separate(elisa_data, col = \"information\", \n                            into = c(\"sample_id\", \"dilution\"),\n                            sep = \"\\\\(\")## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 2 rows [1, 2].\nhead(tidy_elisa_data)## # A tibble: 6 × 4\n##   well_id od_450nm sample_id   dilution\n##   <chr>      <dbl> <chr>       <chr>   \n## 1 A1         0.052 \"blank\"     <NA>    \n## 2 A2         0.05  \"secondary\" <NA>    \n## 3 A3         0.069 \"naïve \"    1/250)  \n## 4 A4         0.063 \"1A-1 \"     1/250   \n## 5 A5         0.061 \"1A-1 \"     1/1250  \n## 6 A6         0.122 \"1A-1 \"     1/6250\ntidy_elisa_data <- tidy_elisa_data %>%\n  mutate(dilution = str_extract(dilution, \"(/)[0-9]+\"),\n         dilution = str_replace(dilution, \"/\", \"\"),\n         dilution = as.numeric(dilution))\n\ntidy_elisa_data <- tidy_elisa_data %>%\n  select(well_id, sample_id, dilution, od_450nm)\n\nhead(tidy_elisa_data)## # A tibble: 6 × 4\n##   well_id sample_id   dilution od_450nm\n##   <chr>   <chr>          <dbl>    <dbl>\n## 1 A1      \"blank\"           NA    0.052\n## 2 A2      \"secondary\"       NA    0.05 \n## 3 A3      \"naïve \"         250    0.069\n## 4 A4      \"1A-1 \"          250    0.063\n## 5 A5      \"1A-1 \"         1250    0.061\n## 6 A6      \"1A-1 \"         6250    0.122"},{"path":"flow-cytometry.html","id":"flow-cytometry","chapter":"6 Flow cytometry","heading":"6 Flow cytometry","text":"Flow cytometry data can quantified many different ways different techniques. purpose data analyses, manual gating achieved FlowJo cell frequencies populations exported .csv file. .csv file primary input R pipeline aims output box plots gated cell population.example data set innate response study whcih investigated immune response lungs first 28 days infection.","code":""},{"path":"flow-cytometry.html","id":"loading-packages","chapter":"6 Flow cytometry","heading":"6.1 Loading packages","text":"","code":"\nlibrary(readxl)\nlibrary(ggplot2)\nlibrary(RColorBrewer)\nlibrary(dplyr)\nlibrary(tidyverse)\nlibrary(scales)## \n## Attaching package: 'scales'## The following object is masked from 'package:purrr':\n## \n##     discard## The following object is masked from 'package:readr':\n## \n##     col_factor\nlibrary(stringr)\nlibrary(tidyr)\nlibrary(knitr)\nlibrary(forcats)\nlibrary(broom)\nlibrary(ggfortify)\nlibrary(stats)\nlibrary(ggpubr)\nlibrary(grDevices)\nlibrary(rstatix)## \n## Attaching package: 'rstatix'## The following object is masked from 'package:stats':\n## \n##     filter\nlibrary(writexl)"},{"path":"flow-cytometry.html","id":"panel-information","chapter":"6 Flow cytometry","heading":"6.2 panel information","text":"","code":"\n# antibody_panel <- read_excel"},{"path":"flow-cytometry.html","id":"loading-data","chapter":"6 Flow cytometry","heading":"6.3 Loading data","text":"","code":"\nDf <- read_excel(\"DATA/innate_normalizedto45.xlsx\", sheet = \"CD3CD11b No Day 14\")\n\nmarker_legend <- read_excel(\"DATA/marker legend.xlsx\")\n\n# Remove Freq of Parent columns\nDf1 <- Df %>% \n  select(-matches(\"Parent\"))\n# Remove \"Leukocytes/LIVE/Single Cells/\" from col names\nnames(Df1) <- str_remove(names(Df1), \"Leukocytes/LIVE/Single Cells/\")\n\nDf1 <- Df1 %>%\n  rename_all(funs(str_replace(., \"\\\\|.+\", \"\")))# Remove \"|Freq of...\" from col names## Warning: `funs()` was deprecated in dplyr 0.8.0.\n## Please use a list of either functions or lambdas: \n## \n##   # Simple named list: \n##   list(mean = mean, median = median)\n## \n##   # Auto named with `tibble::lst()`: \n##   tibble::lst(mean, median)\n## \n##   # Using lambdas\n##   list(~ mean(., trim = .2), ~ median(., na.rm = TRUE))\n## This warning is displayed once every 8 hours.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated.\nDf1 <- Df1 %>%\n  rename_all(funs(str_replace_all(., \"\\\\/Q[:digit:]+\\\\:\", \"\"))) %>%\n  rename_all(funs(str_replace(., \"\\\\/\", \" \"))) %>%\n  rename_all(funs(str_replace(., \"\\\\,\", \" \"))) %>%\n  rename_all(funs(str_replace(., \"\\\\ \\\\,\", \" \")))\n\n# str_extract_all(names(Df1), \"[:alpha:]+[:digit:]+[\\\\+\\\\-]\")\n# \n# \n# \n# \n# \n# \n# marker_select <- function(col_title) {\n#   marker_df <- str_detect(names(DATA1), \"[\\\\+\\\\-]\") \n#   return(marker_df)\n# }"},{"path":"flow-cytometry.html","id":"making-the-data-tidy-for-plotting","chapter":"6 Flow cytometry","heading":"6.4 Making the data tidy for plotting","text":"","code":"\ntidy_Df1 <- pivot_longer(data = Df1, cols =  starts_with(\"CD45+\"), names_to = \"cell_types\", values_to = \"percentage_of_CD45\") \n\ntidy_Df1 <- tidy_Df1 %>%\n  separate(col = \"SAMPLE\", into = c(\"day\", \"replicate\"))\n\n\ntidy_Df1 %>%\n  select(cell_types) %>%\n  unique()## # A tibble: 128 × 1\n##    cell_types                          \n##    <chr>                               \n##  1 \"CD45+ \"                            \n##  2 \"CD45+ CD3-   CD11b+ \"              \n##  3 \"CD45+ CD3-   CD11b+ CD25+ \"        \n##  4 \"CD45+ CD3-   CD11b+ CD103+ \"       \n##  5 \"CD45+ CD3-   CD11b+ gamma_delta \"  \n##  6 \"CD45+ CD3-   CD11b+ NKp46+ \"       \n##  7 \"CD45+ CD3-   CD11b+ CD11c+  CD64- \"\n##  8 \"CD45+ CD3-   CD11b+ CD11c-  CD64- \"\n##  9 \"CD45+ CD3-   CD11b+ CD86-  CD64+ \" \n## 10 \"CD45+ CD3-   CD11b+ CD86+  CD64+ \" \n## # … with 118 more rows\ntidy_Df1 <- tidy_Df1 %>%\n  filter(percentage_of_CD45 > 0.005)\n\nhead(tidy_Df1, n=10)## # A tibble: 10 × 4\n##    day   replicate cell_types                           percentage_of_CD45\n##    <chr> <chr>     <chr>                                             <dbl>\n##  1 CNT   1         \"CD45+ \"                                          82.9 \n##  2 CNT   1         \"CD45+ CD3-   CD11b+ \"                            29.3 \n##  3 CNT   1         \"CD45+ CD3-   CD11b+ CD25+ \"                       0.88\n##  4 CNT   1         \"CD45+ CD3-   CD11b+ CD103+ \"                      0.75\n##  5 CNT   1         \"CD45+ CD3-   CD11b+ gamma_delta \"                 4.77\n##  6 CNT   1         \"CD45+ CD3-   CD11b+ NKp46+ \"                      7.3 \n##  7 CNT   1         \"CD45+ CD3-   CD11b+ CD11c+  CD64- \"               3.65\n##  8 CNT   1         \"CD45+ CD3-   CD11b+ CD11c-  CD64- \"              24.3 \n##  9 CNT   1         \"CD45+ CD3-   CD11b+ CD86-  CD64+ \"                0.43\n## 10 CNT   1         \"CD45+ CD3-   CD11b+ CD86+  CD64+ \"                0.85\n# Select CD3 & CD11b populations and create new data frames \n \nCD3pos_CD11bneg <- tidy_Df1 %>%\n  filter(str_detect(cell_types, \"CD3\\\\+ + CD11b\\\\-\")) \n\nCD3neg_CD11bpos <- tidy_Df1 %>%\n  filter(str_detect(cell_types, \"CD3\\\\- + CD11b\\\\+\")) \n\nCD3neg_CD11bneg <- tidy_Df1 %>%\n  filter(str_detect(cell_types, \"CD3\\\\- + CD11b\\\\-\"))"},{"path":"flow-cytometry.html","id":"boxplot","chapter":"6 Flow cytometry","heading":"6.5 boxplot","text":"","code":"\nCD3pos_CD11bneg_bar_plot <- CD3pos_CD11bneg %>%\nmutate(day = fct_relevel(day,\n            \"CNT\", \"D3\", \"D7\",\n            \"D28\")) %>%\n  ggplot(aes(x = day, y = percentage_of_CD45, fill= day)) +\n  stat_boxplot( aes(day, percentage_of_CD45), \n    geom='errorbar', linetype=1, width=0.5)+  \n  geom_boxplot(aes(day, percentage_of_CD45)) + \n  facet_wrap(~cell_types, scale = \"free_y\", labeller = label_wrap_gen(width=15), ncol = 5, nrow = 20) + \n  theme_bw() + \n  theme(axis.text.x = element_blank(), axis.text.y = element_text(size = 20), \n        axis.title.x = element_text(size = 20, face = \"bold\"), \n        axis.title.y = element_text(size = 20, face = \"bold\"), \n        legend.text = element_text(size = 20), \n        legend.title = element_text(size = 20), \n        plot.title = element_text(color=\"black\", size=30, face=\"bold\")) + \n  labs (y=\"Percentage of CD45\", x = \"Day\") + \n  theme(strip.text = element_text(size=12, face = \"bold\")) + theme(legend.position=\"bottom\") +\n  ggtitle(\"Changes in immune cell populations (lung) CD3+ CD11b-\") +\n  stat_compare_means(label = \"p.signif\", method = \"t.test\",\n                     ref.group = \"CNT\")\n\n\n\nCD3neg_CD11bpos_bar_plot <- CD3neg_CD11bpos %>%\nmutate(day = fct_relevel(day, \n            \"CNT\", \"D3\", \"D7\", \n            \"D28\")) %>%\n  ggplot(aes(x = day, y = percentage_of_CD45, fill= day)) +\n  stat_boxplot( aes(day, percentage_of_CD45), \n    geom='errorbar', linetype=1, width=0.5)+  \n  geom_boxplot( aes(day, percentage_of_CD45)) + \n  facet_wrap(~cell_types, scale = \"free_y\", labeller = label_wrap_gen(width=15), ncol = 5, nrow = 20) + \n  theme_bw() + \n  theme(axis.text.x = element_blank(), axis.text.y = element_text(size = 20), \n        axis.title.x = element_text(size = 20, face = \"bold\"), \n        axis.title.y = element_text(size = 20, face = \"bold\"), \n        legend.text = element_text(size = 20), \n        legend.title = element_text(size = 20), \n        plot.title = element_text(color=\"black\", size=30, face=\"bold\")) + \n  labs (y=\"Percentage of CD45\", x = \"Day\") + \n  theme(strip.text = element_text(size=12, face = \"bold\")) + theme(legend.position=\"bottom\") +\n  ggtitle(\"Changes in immune cell populations (lung) CD3- CD11b+\") +\n  stat_compare_means(label = \"p.signif\", method = \"t.test\",\n                     ref.group = \"CNT\")\n\n\n\nCD3neg_CD11bneg_bar_plot <- CD3neg_CD11bneg %>%\nmutate(day = fct_relevel(day, \n            \"CNT\", \"D3\", \"D7\", \n            \"D28\")) %>%\n  ggplot(aes(x = day, y = percentage_of_CD45, fill= day)) +\n  stat_boxplot( aes(day, percentage_of_CD45), \n    geom='errorbar', linetype=1, width=0.5)+  \n  geom_boxplot( aes(day, percentage_of_CD45)) + \n  facet_wrap(~cell_types, scale = \"free_y\", labeller = label_wrap_gen(width=15), ncol = 5, nrow = 20) + \n  theme_bw() + \n  theme(axis.text.x = element_blank(), axis.text.y = element_text(size = 20), \n        axis.title.x = element_text(size = 20, face = \"bold\"), \n        axis.title.y = element_text(size = 20, face = \"bold\"), \n        legend.text = element_text(size = 20), \n        legend.title = element_text(size = 20), \n        plot.title = element_text(color=\"black\", size=30, face=\"bold\")) + \n  labs (y=\"Percentage of CD45\", x = \"Day\") + \n  theme(strip.text = element_text(size=12, face = \"bold\")) + theme(legend.position=\"bottom\") +\n  ggtitle(\"Changes in immune cell populations (lung) CD3- CD11b-\") +\n  stat_compare_means(label = \"p.signif\", method = \"t.test\",\n                     ref.group = \"CNT\")\n\nCD3pos_CD11bneg_bar_plot\n# CD3neg_CD11bpos_bar_plot\n# CD3neg_CD11bneg_bar_plot"},{"path":"pathology.html","id":"pathology","chapter":"7 Pathology","heading":"7 Pathology","text":"","code":""},{"path":"proteomics.html","id":"proteomics","chapter":"8 Proteomics","heading":"8 Proteomics","text":"proteomics data, getting data already collected \npre-processed another part team. following shows example \ntype data get input:data include following columns:Peptide: short string peptides measuredProtein: protein peptides come fromReplicate: identifier sample measurement taken onPrecursor Mz, Precursor Charge, Product Mz, Product Charge,\nFragment Ion, Retention Time: Measurements help identifying peptide\nmeasured (?)Area:Background:Peak Rank:Ratio Dot Product:Total Area Normalized:Total Area RatioLibrary Dot Product:RatioLightToHeavy:DotProductLightToHeavy:[data pre-processed. Softwarei: Skyline]unique replicates file:three groups data labeled “LT,” “H,” “TB” somewhere \nidentifier. can create new column dataset pulls \ntreatment group information:Cfp10acpMAg85AMtbH37Rv|Rv3841|BfrBMtbH37Rv|Rv1837c|GlcBMtbH37Rv|Rv3418c|GroESMtbH37Rv|Rv3248c|SahHMtbH37Rv|Rv2031c|hspX","code":"\nlibrary(tidyverse)\n\nprot_a <- read_csv(\"DATA/Transition Results_CCTSI_A.csv\")## Rows: 3393 Columns: 18\n## ── Column specification ────────────────────────────────────────────────────────\n## Delimiter: \",\"\n## chr  (7): Peptide, Protein, Replicate, Fragment Ion, Ratio Dot Product, Tota...\n## dbl (11): Precursor Mz, Precursor Charge, Product Mz, Product Charge, Retent...\n## \n## ℹ Use `spec()` to retrieve the full column specification for this data.\n## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nprot_a## # A tibble: 3,393 × 18\n##    Peptide     Protein Replicate   `Precursor Mz` `Precursor Char…` `Product Mz`\n##    <chr>       <chr>   <chr>                <dbl>             <dbl>        <dbl>\n##  1 QELDEISTNIR Cfp10   091322_LT1            659.                 2        1061.\n##  2 QELDEISTNIR Cfp10   091322_LT2            659.                 2        1061.\n##  3 QELDEISTNIR Cfp10   091322_LT3            659.                 2        1061.\n##  4 QELDEISTNIR Cfp10   091322_LT4            659.                 2        1061.\n##  5 QELDEISTNIR Cfp10   091322_LT5            659.                 2        1061.\n##  6 QELDEISTNIR Cfp10   091322_LT6            659.                 2        1061.\n##  7 QELDEISTNIR Cfp10   091322_LT7            659.                 2        1061.\n##  8 QELDEISTNIR Cfp10   091322_LT8            659.                 2        1061.\n##  9 QELDEISTNIR Cfp10   091322_LT10           659.                 2        1061.\n## 10 QELDEISTNIR Cfp10   091322_LT11           659.                 2        1061.\n## # … with 3,383 more rows, and 12 more variables: `Product Charge` <dbl>,\n## #   `Fragment Ion` <chr>, `Retention Time` <dbl>, Area <dbl>, Background <dbl>,\n## #   `Peak Rank` <dbl>, `Ratio Dot Product` <chr>,\n## #   `Total Area Normalized` <chr>, `Total Area Ratio` <chr>,\n## #   `Library Dot Product` <dbl>, RatioLightToHeavy <dbl>,\n## #   DotProductLightToHeavy <dbl>\nprot_a %>% \n  pull(Replicate) %>% \n  unique()##  [1] \"091322_LT1\"  \"091322_LT2\"  \"091322_LT3\"  \"091322_LT4\"  \"091322_LT5\" \n##  [6] \"091322_LT6\"  \"091322_LT7\"  \"091322_LT8\"  \"091322_LT10\" \"091322_LT11\"\n## [11] \"091322_LT12\" \"091322_LT13\" \"091322_LT14\" \"091322_H1\"   \"091322_H2\"  \n## [16] \"091322_H3\"   \"091322_H4\"   \"091322_H5\"   \"091322_H6\"   \"091322_H7\"  \n## [21] \"091322_H8\"   \"091322_H9\"   \"091322_H10\"  \"091322_H11\"  \"091322_H12\" \n## [26] \"091322_H13\"  \"091322_H14\"  \"091322_TB1\"  \"091322_TB2\"  \"091322_TB3\" \n## [31] \"091322_TB4\"  \"091322_TB5\"  \"091322_TB6\"  \"091322_TB7\"  \"091322_TB8\" \n## [36] \"091322_TB9\"  \"091322_TB10\" \"091322_TB11\" \"091322_TB12\"\nprot_a <- prot_a %>% \n  mutate(treatment_group = str_extract(Replicate, \"[A-Z]+\")) \n\nprot_a %>% \n  filter(Peptide == first(Peptide)) %>% \n  group_by(treatment_group) %>% \n  count()## # A tibble: 3 × 2\n## # Groups:   treatment_group [3]\n##   treatment_group     n\n##   <chr>           <int>\n## 1 H                 140\n## 2 LT                130\n## 3 TB                120\nprot_a %>% \n  filter(Peptide == first(Peptide) & \n           Replicate == first(Replicate))## # A tibble: 10 × 19\n##    Peptide     Protein Replicate  `Precursor Mz` `Precursor Charge` `Product Mz`\n##    <chr>       <chr>   <chr>               <dbl>              <dbl>        <dbl>\n##  1 QELDEISTNIR Cfp10   091322_LT1           659.                  2        1061.\n##  2 QELDEISTNIR Cfp10   091322_LT1           659.                  2         832.\n##  3 QELDEISTNIR Cfp10   091322_LT1           659.                  2         703.\n##  4 QELDEISTNIR Cfp10   091322_LT1           659.                  2         590.\n##  5 QELDEISTNIR Cfp10   091322_LT1           659.                  2         503.\n##  6 QELDEISTNIR Cfp10   091322_LT1           664.                  2        1071.\n##  7 QELDEISTNIR Cfp10   091322_LT1           664.                  2         842.\n##  8 QELDEISTNIR Cfp10   091322_LT1           664.                  2         713.\n##  9 QELDEISTNIR Cfp10   091322_LT1           664.                  2         600.\n## 10 QELDEISTNIR Cfp10   091322_LT1           664.                  2         513.\n## # … with 13 more variables: `Product Charge` <dbl>, `Fragment Ion` <chr>,\n## #   `Retention Time` <dbl>, Area <dbl>, Background <dbl>, `Peak Rank` <dbl>,\n## #   `Ratio Dot Product` <chr>, `Total Area Normalized` <chr>,\n## #   `Total Area Ratio` <chr>, `Library Dot Product` <dbl>,\n## #   RatioLightToHeavy <dbl>, DotProductLightToHeavy <dbl>,\n## #   treatment_group <chr>\nprot_a %>% \n  pull(Protein) %>% \n  unique()## [1] \"Cfp10\"                  \"acpM\"                   \"Ag85A\"                 \n## [4] \"MtbH37Rv|Rv3841|BfrB\"   \"MtbH37Rv|Rv1837c|GlcB\"  \"MtbH37Rv|Rv3418c|GroES\"\n## [7] \"MtbH37Rv|Rv3248c|SahH\"  \"MtbH37Rv|Rv2031c|hspX\""},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
